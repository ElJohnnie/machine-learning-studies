Os hiperparâmetros no contexto de aprendizado de máquina são parâmetros externos ao modelo que não são aprendidos durante o treinamento, mas precisam ser definidos antes do início do processo de aprendizagem. Eles afetam diretamente o desempenho e comportamento do modelo durante o treinamento, influenciando coisas como a taxa de aprendizado, o número de épocas de treinamento, o tamanho do lote (batch size), a arquitetura do modelo, entre outros.

Ao contrário dos parâmetros do modelo, que são ajustados automaticamente durante o treinamento para otimizar o desempenho em dados de treinamento, os hiperparâmetros são configurados manualmente ou por meio de técnicas de otimização, como pesquisa em grade ou otimização bayesiana. Encontrar os valores ideais para os hiperparâmetros é uma parte crucial do desenvolvimento de modelos de aprendizado de máquina eficazes.

Exemplos comuns de hiperparâmetros incluem a taxa de aprendizado, o número de camadas e unidades em uma rede neural, os parâmetros de regularização, entre outros. A escolha apropriada desses hiperparâmetros pode ter um impacto significativo no desempenho e na capacidade do modelo de generalizar para novos dados.